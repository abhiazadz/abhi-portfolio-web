<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Project Inner Page</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/me2.jpg" rel="icon">
  <link href="assets/img/me2.jpg" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Satisfy" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/bootstrap-icons/bootstrap-icons.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/glightbox/css/glightbox.min.css" rel="stylesheet">
  <link href="assets/vendor/swiper/swiper-bundle.min.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="w-100 fixed-top d-flex justify-content-center align-items-center header">
    <nav id="navbar" class="navbar">
      <ul>
        <li><a class="nav-link scrollto active" href="index.html#hero">Home</a></li>
        <li><a class="nav-link scrollto" href="index.html#about">About</a></li>
        <!--li><a class="nav-link scrollto" href="#projects">Projects</a-->
        <li class="dropdown"><a class="nav-link scrollto" href="#projects"><span>Projects</span> <i class="bi bi-chevron-down"></i></a>
          <ul>
            <li><a href="project-DDP.html" target="_blank">DDP-Kuka IIWA</a></li>
            <li><a href="project-CERNER.html" target="_blank">CERNER imaging project</a></li>
            <li><a href="project-CIIRC.html" target="_blank">CIIRC- detection on Jetson nano</a></li>
            <li><a href="project-INFYU.html" target="_blank">InfyU labs - Grain detector</a></li>
            <li><a href="project-NUT.html" target="_blank">NUT- Tapping screw</a></li>
            <li><a href="project-BETIC.html" target="_blank">BeTiC - Ergonomic crutch</a></li>
            <li><a href="project-HTIC.html" target="_blank">HTIC - Surgical robot</a></li>
          </ul>
        </li>
        <li><a class="nav-link scrollto" href="index.html#resume">Resume</a></li>
        <li><a class="nav-link scrollto " href="index.html#portfolio">Portfolio</a></li>
        <li><a class="nav-link scrollto" href="index.html#blogs">Blogs</a></li>
        <li class="dropdown"><a href="#"><span>Sitemap</span> <i class="bi bi-chevron-down"></i></a>
          <ul>
            <li><a href="index.html#projects">Projects</a></li>
            <li class="dropdown"><a href="#"><span>Academics</span> <i class="bi bi-chevron-right"></i></a>
              <ul>
                <li><a href="edu-timeline-web-main\index.html" target="_blank">Education and Awards</a></li>
                <li><a href="iitm_course_list.html">IITM course</a></li>
                <li><a href="cvut_course_list.html">ČVUT courses</a></li>
              </ul>
            </li>
            <li><a href="index.html#portfolio">Art portfolio</a></li>
            <li><a href="#">My Visual diary</a></li>
            <li><a href="#">Yoga</a></li>
          </ul>
        </li>
        <li><a class="nav-link scrollto" href="index.html#contact">Contact</a></li>
      </ul>
      <i class="bi bi-list mobile-nav-toggle"></i>
    </nav><!-- .navbar -->

  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Project Description
          </h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>Inner Page</li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

    <section class="inner-page">
      <div class="container">

        <div class="row text-right my-custom-row align-items-center">
          <div class="col-sm-6 offset-0">
            <h1>Real-time detection of minuscule parts in collaborative robotics</h1>
            <br>
            <li><strong>OBJECTIVE:</strong> Detection of miniature parts in Human-Robot interaction assembly line on Nvidia Jetson Nano micro-controller and Intel Realsense depth camera 435i.</li>
            <li><strong>OUTCOME:</strong> Live detection of tiny parts with Full HD imaging was optimised 61x faster in ROS architecture.</li>
            <li><strong>DOMAIN:</strong> Computer Vision, ROS, Micocontroller.</li><br>
            <div class="row text-right justify-content-center align-items-center">
              <a href="https://github.com/abhiazadz/Fast-BGsub-object-localisation" target="_blank" role="button" class="btn btn-warning btn-sm">Github project Link</a>
            </div>
          </div>
          <div class="col-sm-6 offset-0">
            <br>
            <div class="row text-center my-custom-row justify-content-center align-items-center">
              <img src="assets/img/projects/CIIRC/pipeline_U.png" alt=""  class="rounded"  />
              fig 1. Optimised detection pipeline on Jetson-nano 
            </div>
          </div>
        </div>
        <div class="row text-right my-custom-row align-items-center">
          <div class="col-sm-9 offset-0">
            <h3>Background</h3>
            As a part of Collaborative Robotics operative Workspace project, 
            my internship project was focused on improving Object detection module at slave robot ends in the assembly line workspace.
            <br><br>
            The setup consists of a Master system controlling the whole assembly line and Robots. 
            The robots are treated as slave and have a their own imaging uint as the Intel realsense camera and a processing 
            unit as Jetson nano which is compact powerful computer that lets you run multiple neural networks in parallel for applications 
            like image classification, object detection, segmentation, and speech processing. 
            <br><br>
            Our goal was to reduce delay and the load in Master by leveraging the processing capabilities of Jetson nano in a limiting processing power scenario.
            <br><br>

            <h3>Problem statement</h3>
            We wanted achieve Object detection of small machine parts(like nut, bolts) in the assembly line at the slaves in Jetson nano, 
            which requires high resolution images to resolve small components but with the limiting processing capabilities of the slaves, 
            object detection in HD imagescan’t be performed in real time. Hence we want to optimise out Object detection process with additional 
            preprocessing that could make the process of object detection seamless at the slave end. 
            <br><br>

            Various image traditional and advanced image processing techniques were studied and compared using profiling of various functions 
            in python to achieve the object localisation in factors in 10 milliseconds.
            <br><br>


            
          </div>
          <div class="col-sm-3 offset-0">
            <iframe width="300" height="500" src="https://www.youtube.com/embed/Se07gom3FhE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
          </div>

          <div class="row text-right my-custom-row align-items-center">
            <div class="col-sm-12 offset-0">
              <h3>Method and pipeline</h3>

              Raw image in HD stream is published as a ROS message by the intel realsense camera node which is. 
              Using CV_Bridge ROS message is converted into readable cv2 arrays for further preprocessing.
              <br><br>

              As soon as the program is started, we assume that the workspace is empty, the background is captured and saved. This saved empty background is used for background subtraction to segment out the newly introduced objects in the workspace. We keep a threshold value to tackle noise, shadow and lighting variations. 
              <br><br>

              Once we perform background subtraction, we get the segmentation of the newly introduced parts in the robot workspace. Using edge detection techniques, various objects are localised and cropped images of these small objects are cut out which reduces the dimensionality by factors of 100. 
              <br><br>

              These cropped frames are then pushed for object detection to predict their names or class labels. The master subscribes the object detection results are published by the slaves and incooperate the visual scene for planning, collision avoidance and human-collaborative tasks in real-time,
              <br><br>
            </div>
          </div>



        </div>
        <div class="row text-right my-custom-row align-items-center">
          <div class="col-sm-8 offset-0">
            <h3>Collaborative robotics workspace</h3>

            The System consists of Masters and slaves, with robots in the operating end and a realtime vision stream for feedback and planning. ROS- Robotic Operating System was used as the architecture framework for the whole project, programmed in Python.
            <br><br>
            The Robots are the Slave systems that operates in the assembly line.
            <br><br>
            Each slave system consists of two modules, 
            <ul>
              <li>The <strong>manipulation module</strong> consists of a Robotic arm.</li>
              <li>The <strong>Computer vision module</strong> consists of a Jetson nano for processing and an Intel Realsense depth 435i camera for imaging in the local workspace.  </li> 
            </ul>

            The slaves performs the manipulation as commanded by the master and the computer vision module performs object detection and takes care of the visual feedback in real time.
            <br><br>
            Master controls the assembly system, robotic arm plannings, receives slave’s  feedbacks and  based on it the master takes appropriate decision in real-time.
            <br><br>
            A typical object localisation and segmentation of various parts(6-8 parts) in a HD live stream could be be achieved in less than <strong>40 milliseconds</strong>.
          </div>
          <div class="col-sm-4 offset-0">
            <div class="row text-center my-custom-row justify-content-center align-items-center"></div>
              <img src="assets/img/projects/CIIRC/table_top_camera.png" alt=""  width="400" class="rounded"  />
              <br>fig 2. Experiment and test setup
            </div>
          </div>
        </div>

      </div>

      <div class="row text-center my-custom-row align-items-center">
        <div class="col-sm-12 offset-0">
          <div class="row text-center my-custom-row justify-content-center align-items-center"></div>
            <img src="assets/img/projects/CIIRC/crow_pipeline_straight.png" alt="" height ="210" class="rounded"  />
            <br>fig 3. Object detection Workflow
          </div>
        </div>
      </div>
    </section>
    <h2><u>
    

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">
    <div class="container">
      <h3>Abhinav Azad</h3>
      <p>I hope you enjoyed going through my personal website, portfolio and blogs. You can also follow me here.</p>
      <div class="social-links">
        <a href="https://twitter.com/abhiazads" class="twitter"><i class="bx bxl-twitter"></i></a>
        <a href="https://www.facebook.com/abhinav.azad.1" class="facebook"><i class="bx bxl-facebook"></i></a>
        <a href="https://www.instagram.com/abhinavazad/" class="instagram"><i class="bx bxl-instagram"></i></a>
        <a href="https://www.linkedin.com/in/abhinav-azad-abbb1272/" class="linkedin"><i class="bx bxl-linkedin"></i></a>
        <a href="https://github.com/abhiazadz" class="github"><i class="bx bxl-github"></i></a>

      </div>
      <div class="copyright">
        &copy; Copyright <strong><span>Abhi</span></strong>. <br>All Rights Reserved
      </div>
      <div class="credits">
        <!-- Designed by Abhinav using Bootstrap 5.0-->
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top d-flex align-items-center justify-content-center"><i class="bi bi-arrow-up-short"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/glightbox/js/glightbox.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/purecounter/purecounter.js"></script>
  <script src="assets/vendor/swiper/swiper-bundle.min.js"></script>
  <script src="assets/vendor/waypoints/noframework.waypoints.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>